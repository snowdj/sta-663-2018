{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import daft\n",
    "from IPython.display import Image\n",
    "import pystan\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain specific languages (DSL)\n",
    "\n",
    "A simplified computer language for working in a specific domain. Some examples of DSLs that you are already familiar with include\n",
    "\n",
    "- regular expressions for working with text\n",
    "- SQL for working with relational databases\n",
    "- LaTeX for typesetting documents\n",
    "\n",
    "Probabilistic programming languages are DSLs for dealing with models involving random variables and uncertainty. We will introduce the `Stan` probabilistic programming languages in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stan and PyStan references\n",
    "\n",
    "- [Paper describing Stan](http://www.stat.columbia.edu/~gelman/research/unpublished/stan-resubmit-JSS1293.pdf)\n",
    "- [Stan documentation](http://mc-stan.org/users/documentation/index.html)\n",
    "- [Stan examples](https://github.com/stan-dev/example-models/wiki)\n",
    "- [PyStan docs](http://pystan.readthedocs.org/en/latest/)\n",
    "- [PyStan GitHub page](https://github.com/stan-dev/pystan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other packages for probabilistic programming\n",
    "\n",
    "There several alternative packages for probabilistic programming in Python. You might like to explore them by recreating the PyStan examples shown in this notebooks using the following:\n",
    "\n",
    "- [PyMC3](https://github.com/pymc-devs/pymc3)\n",
    "- [Edward](http://edwardlib.org)\n",
    "- [ZhuSuan](https://github.com/thu-ml/zhusuan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In  general, the problem is set up like this:\n",
    "    \n",
    "- We have some observed outcomes $y$ that we want to model\n",
    "- The model is formulated as a probability distribution with some parameters $\\theta$ to be estimated \n",
    "- We want to estimate the posterior distribution of the model parameters given the data\n",
    "$$\n",
    "P(\\theta \\mid y) = \\frac{P(y \\mid \\theta) \\, P(\\theta)}{\\int P(y \\mid \\theta^*) \\, P(\\theta^*) \\, d\\theta^*}\n",
    "$$\n",
    "- For formulating a specification using probabilistic programming, it is often useful to think of how we would simulated a draw from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We toss a coin $n$ times, observed the number of times $y$ it comes up heads, and want to estimate the expected proportion of times $\\theta$ that it comes up heads. An appropriate likelihood is the binomial, and it is convenient to use the $\\beta$ distribution as the prior. In this case, the posterior is also a beta distribution, and there is a simple closed form formula: if the prior is $\\beta(a, b)$ and we observe $y$ heads and $n-y$ tails in $n$ tosses, then the posterior is $\\beta(a+y, a+(n-y)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pgm = daft.PGM(shape=[2.5, 3.0], origin=[0, -0.5])\n",
    "\n",
    "pgm.add_node(daft.Node(\"alpha\", r\"$\\alpha$\", 0.5, 2, fixed=True))\n",
    "pgm.add_node(daft.Node(\"beta\", r\"$\\beta$\", 1.5, 2, fixed=True))\n",
    "pgm.add_node(daft.Node(\"p\", r\"$p$\", 1, 1))\n",
    "pgm.add_node(daft.Node(\"n\", r\"$n$\", 2, 0, fixed=True))\n",
    "pgm.add_node(daft.Node(\"y\", r\"$y$\", 1, 0, observed=True))\n",
    "\n",
    "pgm.add_edge(\"alpha\", \"p\")\n",
    "pgm.add_edge(\"beta\", \"p\")\n",
    "pgm.add_edge(\"n\", \"y\")\n",
    "pgm.add_edge(\"p\", \"y\")\n",
    "\n",
    "pgm.render()\n",
    "plt.close()\n",
    "pgm.figure.savefig(\"bias.png\", dpi=300)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"bias.png\", width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytical solution\n",
    "\n",
    "Illustrating what $y$, $\\theta$, posterior, likelihood, prior, MLE and MAP refer to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "h = 61\n",
    "p = h/n\n",
    "rv = stats.binom(n, p)\n",
    "mu = rv.mean()\n",
    "\n",
    "a, b = 10, 10\n",
    "prior = stats.beta(a, b)\n",
    "post = stats.beta(h+a, n-h+b)\n",
    "ci = post.interval(0.95)\n",
    "\n",
    "thetas = np.linspace(0, 1, 200)\n",
    "plt.plot(thetas, prior.pdf(thetas), label='Prior', c='blue')\n",
    "plt.plot(thetas, post.pdf(thetas), label='Posterior', c='red')\n",
    "plt.plot(thetas, n*stats.binom(n, thetas).pmf(h), label='Likelihood', c='green')\n",
    "plt.axvline((h+a-1)/(n+a+b-2), c='red', linestyle='dashed', alpha=0.4, label='MAP')\n",
    "plt.axvline(mu/n, c='green', linestyle='dashed', alpha=0.4, label='MLE')\n",
    "plt.xlabel(r'$\\theta$', fontsize=14)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `stan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'n': 100,\n",
    "    'y': 61,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "Write your Stan code here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the C++ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel(model_code=code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sm.model_cppcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_map = sm.optimizing(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_map.get('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=data, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the MCMC fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit.stansummary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting `n_eff` and `Rhat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective sample size\n",
    "\n",
    "$$\n",
    "\\hat{n}_{eff} = \\frac{mn}{1 + 2 \\sum_{t=1}^T \\hat{\\rho}_t}\n",
    "$$\n",
    "\n",
    "where $m$ is the number of chains, $n$ the number of steps per chain, $T$ the time when the autocorrelation first becomes negative, and $\\hat{\\rho}_t$ the autocorrelation at lag $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gelman-Rubin $\\widehat{R}$\n",
    "\n",
    "$$\n",
    "\\widehat{R} = \\frac{\\widehat{V}}{W}\n",
    "$$\n",
    "\n",
    "where $W$ is the within-chain variance and $\\widehat{V}$ is the posterior variance estimate for the pooled traces.  Values greater than one indicate that one or more chains have not yet converged.\n",
    "\n",
    "Discrad burn-in steps for each chain. The idea is to see if the starting values of each chain come from the same distribution as the stationary state. \n",
    "\n",
    "- $W$ is the number of chains $m \\times$ the variacne of each individual chain\n",
    "- $B$ is the number of steps $n \\times$ the variance of the chain means\n",
    "- $\\widehat{V}$ is the weigthed average $(1 - \\frac{1}{n})W + \\frac{1}{n}B$\n",
    "\n",
    "The idea is that $\\widehat{V}$ is an unbiased estimator of $W$ if the starting values of each chain come from the same distribution as the stationary state. Hence if $\\widehat{R}$ differs significantly from 1, there is probably no convergence and we need more iterations. This is done for each parameter $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\widehat{R}$ is a measure of chain convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = fit.extract(None, permuted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.model_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2)\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.plot(ps[:, i, 0])\n",
    "    ax.set_title('Chain %d' % (i+1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = fit.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = params['p']\n",
    "plt.subplot(121)\n",
    "plt.hist(p, 20, alpha=0.5)\n",
    "plt.subplot(122)\n",
    "plt.plot(p, alpha=0.5)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin toss as Bernoulli model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file bernoulli_model.stan\n",
    "\n",
    "Write your Stan code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.random.choice([0,1], 100, p=[0.6, 0.4])\n",
    "data = {\n",
    "    'N': len(y),\n",
    "    'y': y\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel('bernoulli_model.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=data, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = sm.optimizing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAP maximizes the log probability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = np.linspace(0, 1, 100)\n",
    "plt.plot(xi, [fit.log_prob(np.log(x) - np.log(1-x)) for x in xi])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan automatically transforms variables so as to work with unconstrained optimization. Knowing this, we can try to replicate the optimization procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0 = 0.1\n",
    "x0 = np.log(p0) - np.log(1 - p0)\n",
    "sol = minimize(fun=lambda x: -fit.log_prob(x), x0=x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(sol.x)/(1 + np.exp(sol.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "Another simple example of a probabilistic model is linear regression\n",
    "\n",
    "$$\n",
    "y = ax + b + \\epsilon\n",
    "$$\n",
    "\n",
    "with $\\epsilon \\sim N(0, \\sigma^2)$.\n",
    "\n",
    "We can think of the simulation model as sampling $y$ from the probability distribution \n",
    "\n",
    "$$\n",
    "y \\sim N(ax + b, \\sigma^2)\n",
    "$$\n",
    "\n",
    "and the parameter $\\theta = (a, b, \\sigma)$ is to be estimated (as posterior probability, MLE or MAP). To complete the model, we need to specify prior distributions for $a$, $b$ and $\\sigma$. For example, if the observations $y$ are standardized to have zero mean and unit standard distribution, we can use\n",
    "\n",
    "$$\n",
    "a \\sim N(0, 10) \\\\\n",
    "b \\sim N(0, 10) \\\\\n",
    "\\sigma \\sim \\vert{N(0, 1)}\n",
    "$$\n",
    "\n",
    "To get a more robust fit that is less sensitive to outliers, we can use a student-T distribution for $y$\n",
    "\n",
    "$$\n",
    "y \\sim t(ax + b, \\sigma^2, \\nu)\n",
    "$$\n",
    "\n",
    "with an extra parameter $\\nu$ for the degrees of freedom for which we also need to specify a prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the PGM.\n",
    "pgm = daft.PGM(shape=[4.0, 3.0], origin=[-0.3, -0.7])\n",
    "\n",
    "# Hierarchical parameters.\n",
    "pgm.add_node(daft.Node(\"alpha\", r\"$\\alpha$\", 0.5, 2))\n",
    "pgm.add_node(daft.Node(\"beta\", r\"$\\beta$\", 1.5, 2))\n",
    "pgm.add_node(daft.Node(\"sigma\", r\"$\\sigma$\", 0, 0))\n",
    "\n",
    "# Deterministic variable.\n",
    "pgm.add_node(daft.Node(\"mu\", r\"$\\mu_n$\", 1, 1))\n",
    "\n",
    "# Data.\n",
    "pgm.add_node(daft.Node(\"x\", r\"$x_n$\", 2, 1, observed=True))\n",
    "pgm.add_node(daft.Node(\"y\", r\"$y_n$\", 1, 0, observed=True))\n",
    "\n",
    "# Add in the edges.\n",
    "pgm.add_edge(\"alpha\", \"mu\")\n",
    "pgm.add_edge(\"beta\", \"mu\")\n",
    "pgm.add_edge(\"x\", \"mu\")\n",
    "pgm.add_edge(\"mu\", \"y\")\n",
    "pgm.add_edge(\"sigma\", \"y\")\n",
    "\n",
    "# And a plate.\n",
    "pgm.add_plate(daft.Plate([0.5, -0.5, 2, 2], label=r\"$n = 1, \\cdots, N$\",\n",
    "    shift=-0.1, rect_params={'color': 'white'}))\n",
    "\n",
    "# Render and save.\n",
    "pgm.render()\n",
    "plt.close()\n",
    "pgm.figure.savefig(\"lm.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"lm.png\", width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file linear.stan\n",
    "\n",
    "Write your Stan code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 11\n",
    "_a = 6\n",
    "_b = 2\n",
    "x = np.linspace(0, 1, n)\n",
    "y = _a + _b*x + np.random.randn(n)\n",
    "\n",
    "data = {\n",
    "    'N': n,\n",
    "    'x': x,\n",
    "    'y': y\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and reloading compiled models\n",
    "\n",
    "Since Stan models take a while to compile, we will define two convenience functions to save and load them. For example, this will allow reuse of the mode in a different session or notebook without recompilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(filename, x):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(x, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'linear'\n",
    "filename = '%s.pkl' % model_name\n",
    "if not os.path.exists(filename):\n",
    "    sm = pystan.StanModel('%s.stan' % model_name)\n",
    "    save(filename, sm)\n",
    "else:\n",
    "    sm = load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the original model from the loaded compiled version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm.model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit = sm.sampling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-using the model on a new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 121\n",
    "_a = 2\n",
    "_b = 1\n",
    "x = np.linspace(0, 1, n)\n",
    "y = _a*x + _b + np.random.randn(n)\n",
    "\n",
    "data = {\n",
    "    'N': n,\n",
    "    'x': x,\n",
    "    'y': y\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit2 = sm.sampling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(fit2.stansummary(pars=['alpha', 'beta', 'sigma']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gelman's book has an example where the dose of a drug may be affected to the number of rat deaths in an experiment.\n",
    "\n",
    "| Dose (log g/ml) | # Rats | # Deaths |\n",
    "|-----------------|--------|----------|\n",
    "| -0.896          | 5      | 0        |\n",
    "| -0.296          | 5      | 1        |\n",
    "| -0.053          | 5      | 3        |\n",
    "| 0.727           | 5      | 5        |\n",
    "\n",
    "We will model the number of deaths as a random sample from a binomial distribution, where $n$ is the number of rats and $p$ the probability of a rat dying. We are given $n = 5$, but we believe that $p$ may be related to the drug dose $x$. As $x$ increases the number of rats dying seems to increase, and since $p$ is a probability, we use the following model:\n",
    "\n",
    "$$\n",
    "y \\sim \\text{Bin}(n, p) \\\\\n",
    "\\text{logit}(p) = \\alpha + \\beta x \\\\\n",
    "\\alpha \\sim \\mathcal{N}(0, 5) \\\\\n",
    "\\beta \\sim \\mathcal{N}(0, 10)\n",
    "$$\n",
    "\n",
    "where we set vague priors for $\\alpha$ and $\\beta$, the parameters for the logistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Create the plate diagram for this model using `daft`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical model in Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    N = 4,\n",
    "    x = [-0.896, -0.296, -0.053, 0.727],\n",
    "    y = [0, 1, 3, 5],\n",
    "    n = [5, 5, 5, 5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file dose.stan\n",
    "\n",
    "Write your Stan code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dose'\n",
    "filename = '%s.pkl' % model_name\n",
    "if not os.path.exists(filename):\n",
    "    sm = pystan.StanModel('%s.stan' % model_name)\n",
    "    save(filename, sm)\n",
    "else:\n",
    "    sm = load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=data)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha, beta, *probs = fit.get_posterior_mean()\n",
    "a = alpha.mean()\n",
    "b = beta.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic function\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{e^z}{1 + e^z}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(a, b, x):\n",
    "    \"\"\"Logistic function.\"\"\"\n",
    "    return np.exp(a + b*x)/(1 + np.exp(a + b*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi =  np.linspace(min(data['x']), max(data['x']), 100)\n",
    "plt.plot(xi, logistic(a, b, xi))\n",
    "plt.scatter(data['x'], [y_/n_ for (y_, n_) in zip(data['y'], data['n'])], c='red')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling from prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file dose_prior.stan\n",
    "\n",
    "Write your Stan code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel('dose_prior.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_prior = sm.sampling(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha, beta, *probs, lp = fit_prior.get_posterior_mean()\n",
    "a = alpha.mean()\n",
    "b = beta.mean()\n",
    "p = [prob.mean() for prob in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.random.binomial(5, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi =  np.linspace(min(data['x']), max(data['x']), 100)\n",
    "plt.plot(xi, logistic(a, b, xi))\n",
    "plt.scatter(data['x'], [y_/n_ for (y_, n_) in zip(y, data['n'])], c='red')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling from posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file dose_post.stan\n",
    "\n",
    "Write your Stan code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pystan.StanModel('dose_post.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_post = sm.sampling(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yp = fit_post.extract('yp')['yp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.c_[data['x'], yp.T[:, :6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
